{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434fd006",
   "metadata": {},
   "source": [
    "# Explicações\n",
    "\n",
    "O objetivo aqui é identificar as expressões mais frequentes, onde uma expressão é um conjunto de palavras seguidas das outras.\n",
    "\n",
    "Para tal, primeiro realizamos o split de cada frase (quebrando por espaços), e a partir disso, usamos a classe `NGram` do Spark.\n",
    "\n",
    "Por fim, o NGram realiza a transformação desejada, por exemplo, se você tem a frase splitada, usando N = 3:\n",
    "\n",
    "`[this, is, the, most, cool]`\n",
    "\n",
    "O NGram produzirá como array de saída frases formadas com as palavras em sequência, nesse caso:\n",
    "\n",
    "`[this is the, is the most, the most cool]`\n",
    "\n",
    "Exatamente conforme desejado.\n",
    "\n",
    "Por fim, aplicamos o método explode para transformar os elementos da lista em linhas individuais, e por fim, aplicamos um groupBy para agregar e contar as frases comuns.\n",
    "\n",
    "Link para documentação: https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.feature.NGram.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e758335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/08 22:00:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|this is the most ...|\n",
      "|my significant ot...|\n",
      "|we had a tour to ...|\n",
      "|visited with my w...|\n",
      "|we went in the ni...|\n",
      "|dont hesitate and...|\n",
      "|i enjoyed the tow...|\n",
      "|read through the ...|\n",
      "|this by far was o...|\n",
      "|something you hav...|\n",
      "|the views are bea...|\n",
      "|worth spending a ...|\n",
      "|took the tour to ...|\n",
      "|a fantastic fusio...|\n",
      "|whatever you do i...|\n",
      "|not to miss..beau...|\n",
      "|we visited in the...|\n",
      "|go for sunset and...|\n",
      "|we booked weeks a...|\n",
      "|eiffel tower is j...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length, element_at, size, split, udf, explode, desc, lower\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import NGram\n",
    "import re\n",
    "EXPRESSIONS_SIZE = 3\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.json('file:///home/ec2-user/eiffel-tower-reviews.json').select(lower('text').alias('text'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a94b5",
   "metadata": {},
   "source": [
    "Primeiramente, quebramos strings de entrada por espaços, transformando cada string em um array de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530f2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               words|\n",
      "+--------------------+\n",
      "|[this, is, the, m...|\n",
      "|[my, significant,...|\n",
      "|[we, had, a, tour...|\n",
      "|[visited, with, m...|\n",
      "|[we, went, in, th...|\n",
      "|[dont, hesitate, ...|\n",
      "|[i, enjoyed, the,...|\n",
      "|[read, through, t...|\n",
      "|[this, by, far, w...|\n",
      "|[something, you, ...|\n",
      "|[the, views, are,...|\n",
      "|[worth, spending,...|\n",
      "|[took, the, tour,...|\n",
      "|[a, fantastic, fu...|\n",
      "|[whatever, you, d...|\n",
      "|[not, to, miss..b...|\n",
      "|[we, visited, in,...|\n",
      "|[go, for, sunset,...|\n",
      "|[we, booked, week...|\n",
      "|[eiffel, tower, i...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(split(df.text,' ').alias('words')).na.drop()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedcbb8",
   "metadata": {},
   "source": [
    "Em seguida, aplicamos o transformador `NGram` do Spark, para obter as frases (aqui optamos por n = 3 para o tamanho da expressão) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b24033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|             phrases|\n",
      "+--------------------+--------------------+\n",
      "|[this, is, the, m...|[this is the, is ...|\n",
      "|[my, significant,...|[my significant o...|\n",
      "|[we, had, a, tour...|[we had a, had a ...|\n",
      "|[visited, with, m...|[visited with my,...|\n",
      "|[we, went, in, th...|[we went in, went...|\n",
      "|[dont, hesitate, ...|[dont hesitate an...|\n",
      "|[i, enjoyed, the,...|[i enjoyed the, e...|\n",
      "|[read, through, t...|[read through the...|\n",
      "|[this, by, far, w...|[this by far, by ...|\n",
      "|[something, you, ...|[something you ha...|\n",
      "|[the, views, are,...|[the views are, v...|\n",
      "|[worth, spending,...|[worth spending a...|\n",
      "|[took, the, tour,...|[took the tour, t...|\n",
      "|[a, fantastic, fu...|[a fantastic fusi...|\n",
      "|[whatever, you, d...|[whatever you do,...|\n",
      "|[not, to, miss..b...|[not to miss..bea...|\n",
      "|[we, visited, in,...|[we visited in, v...|\n",
      "|[go, for, sunset,...|[go for sunset, f...|\n",
      "|[we, booked, week...|[we booked weeks,...|\n",
      "|[eiffel, tower, i...|[eiffel tower is,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_gen = NGram(n=EXPRESSIONS_SIZE, inputCol=\"words\", outputCol=\"phrases\")\n",
    "processed_df = ngram_gen.transform(df)\n",
    "\n",
    "processed_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4355d",
   "metadata": {},
   "source": [
    "Em seguida, aplicamos um explode para obter a lista de frases (expressões) presentes no texto original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b61e617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         expressions|\n",
      "+--------------------+\n",
      "|         this is the|\n",
      "|         is the most|\n",
      "|    the most busiest|\n",
      "|most busiest attt...|\n",
      "|busiest atttactio...|\n",
      "| atttaction in paris|\n",
      "|        in paris and|\n",
      "|     paris and there|\n",
      "|       and there are|\n",
      "|      there are some|\n",
      "|       are some nice|\n",
      "|some nice restaur...|\n",
      "| nice restaurants on|\n",
      "|   restaurants on it|\n",
      "|           on it and|\n",
      "|          it and the|\n",
      "|       and the views|\n",
      "|      the views were|\n",
      "|views were specta...|\n",
      "|were spectacular and|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_phrases_df = processed_df.select(explode(processed_df.phrases).alias(\"expressions\"))\n",
    "common_phrases_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db79238",
   "metadata": {},
   "source": [
    "Por fim, com as frases prontas, basta agregar os dados e contar as frases mais frequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e00caaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|      expressions|count|\n",
      "+-----------------+-----+\n",
      "| the eiffel tower| 1607|\n",
      "|       to the top|  795|\n",
      "|        go to the|  490|\n",
      "|  eiffel tower is|  488|\n",
      "|the eiffel tower.|  441|\n",
      "|        up to the|  419|\n",
      "|         to go up|  366|\n",
      "|      to the top.|  362|\n",
      "|       to see the|  352|\n",
      "|     of the tower|  352|\n",
      "|       the top of|  352|\n",
      "|         to go to|  349|\n",
      "|       one of the|  337|\n",
      "|       top of the|  302|\n",
      "|    to the second|  300|\n",
      "|    of the eiffel|  280|\n",
      "|      you have to|  268|\n",
      "|     from the top|  266|\n",
      "|    to the eiffel|  248|\n",
      "|     the tower is|  245|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phrases_frequency = common_phrases_df.groupBy(\"expressions\").count()\n",
    "phrases_frequency.orderBy(desc(\"count\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
